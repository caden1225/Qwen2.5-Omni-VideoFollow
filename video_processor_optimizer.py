#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘å¤„ç†ä¼˜åŒ–æ¨¡å—
åŒ…å«æ‰€æœ‰éªŒè¯æˆåŠŸçš„æŠ½æ ·ã€é™å¸§ã€è°ƒæ•´åŠŸèƒ½
"""

import torch
import gc
import os
import sys
import time
import json
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "qwen-omni-utils" / "src"))

from qwen_omni_utils import process_mm_info

@dataclass
class VideoOptimizationConfig:
    """è§†é¢‘ä¼˜åŒ–é…ç½®ç±»"""
    # å¸§æ•°æ§åˆ¶
    nframes: int = 4                    # ç›´æ¥æŒ‡å®šå¸§æ•°
    fps: Optional[float] = None         # å¸§ç‡ï¼ˆä¸nframesäº’æ–¥ï¼‰
    min_frames: int = 2                 # æœ€å°å¸§æ•°
    max_frames: int = 16                # æœ€å¤§å¸§æ•°
    
    # åˆ†è¾¨ç‡æ§åˆ¶
    resized_height: int = 112           # ç›®æ ‡é«˜åº¦
    resized_width: int = 112            # ç›®æ ‡å®½åº¦
    
    # æ—¶é—´æ§åˆ¶
    video_start: float = 0.0            # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    video_end: Optional[float] = None   # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    
    # åƒç´ é™åˆ¶
    min_pixels: Optional[int] = None    # æœ€å°åƒç´ æ•°
    max_pixels: Optional[int] = None    # æœ€å¤§åƒç´ æ•°
    
    # å†…å­˜ä¼˜åŒ–
    use_half_precision: bool = True     # æ˜¯å¦ä½¿ç”¨float16
    enable_audio: bool = False          # æ˜¯å¦å¯ç”¨éŸ³é¢‘å¤„ç†

class VideoProcessorOptimizer:
    """è§†é¢‘å¤„ç†ä¼˜åŒ–å™¨"""
    
    def __init__(self, config: VideoOptimizationConfig):
        self.config = config
        self.setup_environment()
    
    def setup_environment(self):
        """è®¾ç½®ç¯å¢ƒå˜é‡"""
        # è®¾ç½®è§†é¢‘åƒç´ é™åˆ¶
        if self.config.max_pixels:
            os.environ['VIDEO_MAX_PIXELS'] = str(self.config.max_pixels)
        
        # è®¾ç½®CUDAå†…å­˜åˆ†é…ç­–ç•¥
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    
    def validate_config(self) -> bool:
        """éªŒè¯é…ç½®å‚æ•°"""
        # æ£€æŸ¥fpså’Œnframesä¸èƒ½åŒæ—¶ä½¿ç”¨
        if self.config.fps is not None and self.config.nframes is not None:
            print("âŒ é”™è¯¯ï¼šfpså’Œnframesä¸èƒ½åŒæ—¶ä½¿ç”¨")
            return False
        
        # æ£€æŸ¥åˆ†è¾¨ç‡æ˜¯å¦åˆç†
        if self.config.resized_height < 112 or self.config.resized_width < 112:
            print("âŒ é”™è¯¯ï¼šåˆ†è¾¨ç‡ä¸èƒ½å°äº112x112")
            return False
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´
        if self.config.video_end and self.config.video_start >= self.config.video_end:
            print("âŒ é”™è¯¯ï¼šå¼€å§‹æ—¶é—´å¿…é¡»å°äºç»“æŸæ—¶é—´")
            return False
        
        return True
    
    def get_video_params(self) -> Dict[str, Any]:
        """è·å–è§†é¢‘å¤„ç†å‚æ•°"""
        params = {}
        
        # å¸§æ•°æ§åˆ¶
        if self.config.nframes is not None:
            params['nframes'] = self.config.nframes
        elif self.config.fps is not None:
            params['fps'] = self.config.fps
            params['min_frames'] = self.config.min_frames
            params['max_frames'] = self.config.max_frames
        
        # åˆ†è¾¨ç‡æ§åˆ¶
        params['resized_height'] = self.config.resized_height
        params['resized_width'] = self.config.resized_width
        
        # æ—¶é—´æ§åˆ¶
        if self.config.video_start > 0:
            params['video_start'] = self.config.video_start
        if self.config.video_end:
            params['video_end'] = self.config.video_end
        
        # åƒç´ é™åˆ¶
        if self.config.min_pixels:
            params['min_pixels'] = self.config.min_pixels
        if self.config.max_pixels:
            params['max_pixels'] = self.config.max_pixels
        
        return params
    
    def process_video(self, video_path: str, conversation: list) -> Tuple[bool, Optional[torch.Tensor], Dict[str, Any]]:
        """
        å¤„ç†è§†é¢‘
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            conversation: å¯¹è¯å†…å®¹
            
        Returns:
            (æˆåŠŸæ ‡å¿—, è§†é¢‘å¼ é‡, å¤„ç†ä¿¡æ¯)
        """
        if not self.validate_config():
            return False, None, {}
        
        try:
            # æ£€æŸ¥æ–‡ä»¶
            if not os.path.exists(video_path):
                print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return False, None, {}
            
            file_size = os.path.getsize(video_path) / (1024 * 1024)  # MB
            print(f"ğŸ“¹ å¤„ç†è§†é¢‘: {video_path}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            # è·å–å¤„ç†å‚æ•°
            video_params = self.get_video_params()
            print(f"âš™ï¸ å¤„ç†å‚æ•°: {video_params}")
            
            # åˆ›å»ºå¸¦è§†é¢‘çš„å¯¹è¯
            video_conversation = self._add_video_to_conversation(conversation, video_path, video_params)
            
            # å¤„ç†å¤šåª’ä½“ä¿¡æ¯
            start_time = time.time()
            audios, images, videos = process_mm_info(video_conversation, use_audio_in_video=self.config.enable_audio)
            processing_time = time.time() - start_time
            
            if not videos:
                print("âŒ è§†é¢‘å¤„ç†å¤±è´¥")
                return False, None, {}
            
            video_tensor = videos[0]
            print(f"âœ… è§†é¢‘å¤„ç†æˆåŠŸ")
            print(f"  - å½¢çŠ¶: {video_tensor.shape}")
            print(f"  - å†…å­˜å ç”¨: {video_tensor.element_size() * video_tensor.nelement() / 1024**2:.2f} MB")
            print(f"  - å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
            
            # è½¬æ¢ä¸ºåŠç²¾åº¦ä»¥èŠ‚çœå†…å­˜
            if self.config.use_half_precision and video_tensor.dtype == torch.float32:
                video_tensor = video_tensor.half()
                print(f"  - è½¬æ¢ä¸ºfloat16åå†…å­˜: {video_tensor.element_size() * video_tensor.nelement() / 1024**2:.2f} MB")
            
            # æ”¶é›†å¤„ç†ä¿¡æ¯
            info = {
                'file_size_mb': file_size,
                'processing_time': processing_time,
                'final_shape': list(video_tensor.shape),
                'final_memory_mb': video_tensor.element_size() * video_tensor.nelement() / 1024**2,
                'params_used': video_params
            }
            
            return True, video_tensor, info
            
        except Exception as e:
            print(f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False, None, {}
    
    def _add_video_to_conversation(self, conversation: list, video_path: str, video_params: Dict[str, Any]) -> list:
        """å°†è§†é¢‘æ·»åŠ åˆ°å¯¹è¯ä¸­"""
        # æ·±æ‹·è´å¯¹è¯
        video_conversation = []
        for turn in conversation:
            new_turn = {'role': turn['role'], 'content': []}
            for content in turn['content']:
                if content['type'] == 'video':
                    # æ›¿æ¢è§†é¢‘å†…å®¹
                    new_content = {'type': 'video', 'video': video_path, **video_params}
                    new_turn['content'].append(new_content)
                else:
                    new_turn['content'].append(content.copy())
            video_conversation.append(new_turn)
        
        return video_conversation
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

class VideoOptimizationPresets:
    """è§†é¢‘ä¼˜åŒ–é¢„è®¾é…ç½®"""
    
    @staticmethod
    def get_preset(name: str) -> VideoOptimizationConfig:
        """è·å–é¢„è®¾é…ç½®"""
        presets = {
            'extreme_low_memory': VideoOptimizationConfig(
                nframes=2,
                resized_height=112,
                resized_width=112,
                video_start=0.0,
                video_end=2.0,
                max_pixels=64 * 28 * 28,
                use_half_precision=True,
                enable_audio=False
            ),
            
            'low_memory': VideoOptimizationConfig(
                nframes=4,
                resized_height=112,
                resized_width=112,
                video_start=0.0,
                video_end=3.0,
                max_pixels=128 * 28 * 28,
                use_half_precision=True,
                enable_audio=False
            ),
            
            'balanced': VideoOptimizationConfig(
                nframes=6,
                resized_height=168,
                resized_width=168,
                video_start=0.0,
                video_end=4.0,
                max_pixels=256 * 28 * 28,
                use_half_precision=True,
                enable_audio=False
            ),
            
            'high_quality': VideoOptimizationConfig(
                nframes=8,
                resized_height=224,
                resized_width=224,
                video_start=0.0,
                video_end=5.0,
                max_pixels=512 * 28 * 28,
                use_half_precision=True,
                enable_audio=False
            ),
            
            'custom_math_video': VideoOptimizationConfig(
                nframes=4,
                resized_height=112,
                resized_width=112,
                video_start=0.0,
                video_end=3.0,
                max_pixels=128 * 28 * 28,
                use_half_precision=True,
                enable_audio=False
            )
        }
        
        if name not in presets:
            raise ValueError(f"æœªçŸ¥çš„é¢„è®¾é…ç½®: {name}ã€‚å¯ç”¨é…ç½®: {list(presets.keys())}")
        
        return presets[name]
    
    @staticmethod
    def list_presets() -> list:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é¢„è®¾é…ç½®"""
        return [
            'extreme_low_memory',  # æä½å†…å­˜æ¨¡å¼
            'low_memory',          # ä½å†…å­˜æ¨¡å¼
            'balanced',            # å¹³è¡¡æ¨¡å¼
            'high_quality',        # é«˜è´¨é‡æ¨¡å¼
            'custom_math_video'    # æ•°å­¦è§†é¢‘ä¸“ç”¨æ¨¡å¼
        ]

def load_config_from_file(config_path: str) -> VideoOptimizationConfig:
    """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config_dict = json.load(f)
        
        # åˆ›å»ºé…ç½®å¯¹è±¡
        config = VideoOptimizationConfig(**config_dict)
        return config
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤é…ç½®
        return VideoOptimizationConfig()

def save_config_to_file(config: VideoOptimizationConfig, config_path: str):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        config_dict = {
            'nframes': config.nframes,
            'fps': config.fps,
            'min_frames': config.min_frames,
            'max_frames': config.max_frames,
            'resized_height': config.resized_height,
            'resized_width': config.resized_width,
            'video_start': config.video_start,
            'video_end': config.video_end,
            'min_pixels': config.min_pixels,
            'max_pixels': config.max_pixels,
            'use_half_precision': config.use_half_precision,
            'enable_audio': config.enable_audio
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

if __name__ == "__main__":
    # æµ‹è¯•é¢„è®¾é…ç½®
    print("=== è§†é¢‘ä¼˜åŒ–é¢„è®¾é…ç½®æµ‹è¯• ===")
    
    for preset_name in VideoOptimizationPresets.list_presets():
        print(f"\n--- é¢„è®¾: {preset_name} ---")
        config = VideoOptimizationPresets.get_preset(preset_name)
        print(f"é…ç½®: {config}")
        
        # éªŒè¯é…ç½®
        optimizer = VideoProcessorOptimizer(config)
        if optimizer.validate_config():
            print("âœ… é…ç½®éªŒè¯é€šè¿‡")
        else:
            print("âŒ é…ç½®éªŒè¯å¤±è´¥")
    
    # ä¿å­˜ç¤ºä¾‹é…ç½®
    example_config = VideoOptimizationPresets.get_preset('low_memory')
    save_config_to_file(example_config, 'example_video_config.json')
