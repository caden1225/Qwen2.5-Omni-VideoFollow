#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen2.5-Omni å¤šæ¨¡æ€æ¨ç†äº¤äº’ç•Œé¢
æ”¯æŒè§†é¢‘ã€éŸ³é¢‘+å›¾ç‰‡ã€æ–‡æœ¬+å›¾ç‰‡ç­‰å¤šç§è¾“å…¥æ–¹å¼
"""

import gradio as gr
import os
import sys
import json
import tempfile
import shutil
import logging
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
import threading
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model_inference import ModelManager, InferencePresets
from memory_manager import MemoryPresets, ConfigurableMemoryLoader
from video_utils import VideoProcessor
from video_optimizer import VideoOptimizationPresets, MemoryOptimizedVideoHandler

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GradioApp:
    """Gradioåº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        self.model_manager = ModelManager()
        self.video_processor = VideoProcessor()
        self.memory_loader = ConfigurableMemoryLoader()
        self.current_model_loaded = False
        self.temp_files = []
        self.processing_lock = threading.Lock()
        
        # åŠ è½½é»˜è®¤æ¨¡å‹
        self.initialize_model()
    
    def initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info("åˆå§‹åŒ–æ¨¡å‹...")
            model_path = os.getenv("MODEL_PATH", "/home/caden/workplace/models/Qwen2.5-Omni-3B")
            
            if self.model_manager.load_model_with_config(
                *InferencePresets.get_model_preset("low_vram")
            ):
                self.current_model_loaded = True
                logger.info("æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.error("æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
                
        except Exception as e:
            logger.error(f"æ¨¡å‹åˆå§‹åŒ–å¼‚å¸¸: {e}")
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        with gr.Blocks(
            title="Qwen2.5-Omni å¤šæ¨¡æ€æ¨ç†",
            theme=gr.themes.Soft(),
            css=self.get_custom_css()
        ) as interface:
            
            # æ ‡é¢˜
            gr.Markdown("""
            # ğŸ¤– Qwen2.5-Omni å¤šæ¨¡æ€æ¨ç†å¹³å°
            
            æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼çš„æ™ºèƒ½AIäº¤äº’ï¼ŒåŒ…æ‹¬è§†é¢‘åˆ†æã€è¯­éŸ³ç†è§£ã€å›¾åƒè¯†åˆ«ç­‰åŠŸèƒ½ã€‚
            """)
            
            # æ¨¡å‹é…ç½®åŒºåŸŸ
            with gr.Accordion("âš™ï¸ æ¨¡å‹é…ç½®", open=False):
                model_configs = self.create_model_config_section()
            
            # è¾“å…¥æ–¹å¼é€‰æ‹©
            with gr.Row():
                input_mode = gr.Radio(
                    choices=["ğŸ¬ è§†é¢‘è¾“å…¥", "ğŸµ éŸ³é¢‘+å›¾ç‰‡", "ğŸ“ æ–‡æœ¬+å›¾ç‰‡", "ğŸ’¬ çº¯æ–‡æœ¬"],
                    value="ğŸ¬ è§†é¢‘è¾“å…¥",
                    label="è¾“å…¥æ–¹å¼",
                    info="é€‰æ‹©æ‚¨è¦ä½¿ç”¨çš„è¾“å…¥æ–¹å¼"
                )
            
            # åŠ¨æ€è¾“å…¥åŒºåŸŸ
            input_components = self.create_input_sections(input_mode)
            
            # è¾“å‡ºåŒºåŸŸ
            output_components = self.create_output_section()
            
            # ç³»ç»Ÿä¿¡æ¯
            with gr.Accordion("ğŸ“Š ç³»ç»Ÿä¿¡æ¯", open=False):
                system_components = self.create_system_info_section()
            
            # è®¾ç½®äº‹ä»¶å¤„ç†å™¨
            all_components = {
                **input_components,
                'outputs': output_components,
                'model_configs': model_configs,
                'system': system_components
            }
            self.setup_event_handlers(all_components)
        
        return interface
    
    def create_model_config_section(self):
        """åˆ›å»ºæ¨¡å‹é…ç½®åŒºåŸŸ"""
        with gr.Row():
            model_preset = gr.Dropdown(
                choices=InferencePresets.list_presets(),
                value="low_vram",
                label="æ¨¡å‹é¢„è®¾",
                info="é€‰æ‹©é€‚åˆæ‚¨ç¡¬ä»¶çš„é¢„è®¾é…ç½®"
            )
            
            memory_preset = gr.Dropdown(
                choices=MemoryPresets.list_presets(),
                value="low_vram", 
                label="å†…å­˜é¢„è®¾",
                info="é€‰æ‹©å†…å­˜ç®¡ç†ç­–ç•¥"
            )
        
        with gr.Row():
            load_model_btn = gr.Button("ğŸ”„ é‡æ–°åŠ è½½æ¨¡å‹", variant="secondary")
            model_status = gr.Textbox(
                value="ğŸŸ¢ æ¨¡å‹å·²å°±ç»ª" if self.current_model_loaded else "ğŸ”´ æ¨¡å‹æœªåŠ è½½",
                label="æ¨¡å‹çŠ¶æ€",
                interactive=False
            )
        
        # æ¨¡å‹é…ç½®äº‹ä»¶
        def reload_model(model_preset_val, memory_preset_val):
            try:
                with self.processing_lock:
                    # æ¸…ç†å½“å‰æ¨¡å‹
                    self.model_manager.cleanup()
                    
                    # åŠ è½½æ–°é…ç½®
                    model_config, vram_config = InferencePresets.get_model_preset(model_preset_val)
                    memory_config = MemoryPresets.get_preset(memory_preset_val)
                    
                    # æ›´æ–°å†…å­˜åŠ è½½å™¨é…ç½®
                    self.memory_loader.config = memory_config
                    
                    # é‡æ–°åŠ è½½æ¨¡å‹
                    if self.model_manager.load_model_with_config(model_config, vram_config):
                        self.current_model_loaded = True
                        return "ğŸŸ¢ æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸ"
                    else:
                        self.current_model_loaded = False
                        return "ğŸ”´ æ¨¡å‹åŠ è½½å¤±è´¥"
                        
            except Exception as e:
                logger.error(f"æ¨¡å‹é‡æ–°åŠ è½½å¤±è´¥: {e}")
                self.current_model_loaded = False
                return f"ğŸ”´ åŠ è½½å¤±è´¥: {str(e)}"
        
        load_model_btn.click(
            fn=reload_model,
            inputs=[model_preset, memory_preset],
            outputs=[model_status]
        )
        
        return {
            'model_preset': model_preset,
            'memory_preset': memory_preset, 
            'model_status': model_status,
            'load_model_btn': load_model_btn
        }
    
    def create_input_sections(self, input_mode):
        """åˆ›å»ºè¾“å…¥åŒºåŸŸ"""
        # è§†é¢‘è¾“å…¥
        with gr.Group(visible=True) as video_group:
            gr.Markdown("### ğŸ¬ è§†é¢‘è¾“å…¥")
            with gr.Row():
                with gr.Column(scale=2):
                    video_input = gr.Video(
                        label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶",
                        info="æ”¯æŒMP4, AVI, MOVç­‰æ ¼å¼"
                    )
                    
                    video_prompt = gr.Textbox(
                        label="æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                        placeholder="è¯·æè¿°æ‚¨å¸Œæœ›AIå…³æ³¨çš„å†…å®¹...",
                        lines=2
                    )
                
                with gr.Column(scale=1):
                    video_options = self.create_video_options()
            
            process_video_btn = gr.Button("ğŸš€ åˆ†æè§†é¢‘", variant="primary", size="lg")
        
        # éŸ³é¢‘+å›¾ç‰‡è¾“å…¥
        with gr.Group(visible=False) as audio_image_group:
            gr.Markdown("### ğŸµ éŸ³é¢‘+å›¾ç‰‡è¾“å…¥")
            with gr.Row():
                audio_input = gr.Audio(
                    label="ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶",
                    type="filepath"
                )
                image_input_1 = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡",
                    type="filepath"
                )
            
            audio_image_prompt = gr.Textbox(
                label="æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                placeholder="è¯·æè¿°æ‚¨å¸Œæœ›AIåˆ†æçš„å†…å®¹...",
                lines=2
            )
            
            process_audio_image_btn = gr.Button("ğŸš€ åˆ†æéŸ³é¢‘+å›¾ç‰‡", variant="primary", size="lg")
        
        # æ–‡æœ¬+å›¾ç‰‡è¾“å…¥
        with gr.Group(visible=False) as text_image_group:
            gr.Markdown("### ğŸ“ æ–‡æœ¬+å›¾ç‰‡è¾“å…¥")
            with gr.Row():
                text_input = gr.Textbox(
                    label="è¾“å…¥æ–‡æœ¬",
                    placeholder="è¯·è¾“å…¥æ‚¨è¦åˆ†æçš„æ–‡æœ¬å†…å®¹...",
                    lines=4
                )
                image_input_2 = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡",
                    type="filepath"
                )
            
            process_text_image_btn = gr.Button("ğŸš€ åˆ†ææ–‡æœ¬+å›¾ç‰‡", variant="primary", size="lg")
        
        # çº¯æ–‡æœ¬è¾“å…¥
        with gr.Group(visible=False) as text_group:
            gr.Markdown("### ğŸ’¬ çº¯æ–‡æœ¬å¯¹è¯")
            text_only_input = gr.Textbox(
                label="è¾“å…¥æ–‡æœ¬",
                placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                lines=3
            )
            
            process_text_btn = gr.Button("ğŸš€ å‘é€æ¶ˆæ¯", variant="primary", size="lg")
        
        # è¾“å…¥æ–¹å¼åˆ‡æ¢äº‹ä»¶
        def switch_input_mode(mode):
            visibility = {
                "ğŸ¬ è§†é¢‘è¾“å…¥": (True, False, False, False),
                "ğŸµ éŸ³é¢‘+å›¾ç‰‡": (False, True, False, False), 
                "ğŸ“ æ–‡æœ¬+å›¾ç‰‡": (False, False, True, False),
                "ğŸ’¬ çº¯æ–‡æœ¬": (False, False, False, True)
            }
            
            return [gr.Group(visible=v) for v in visibility.get(mode, (True, False, False, False))]
        
        input_mode.change(
            fn=switch_input_mode,
            inputs=[input_mode],
            outputs=[video_group, audio_image_group, text_image_group, text_group]
        )
        
        return {
            'video_input': video_input,
            'video_prompt': video_prompt,
            'video_options': video_options,
            'process_video_btn': process_video_btn,
            'audio_input': audio_input,
            'image_input_1': image_input_1,
            'audio_image_prompt': audio_image_prompt,
            'process_audio_image_btn': process_audio_image_btn,
            'text_input': text_input,
            'image_input_2': image_input_2,
            'process_text_image_btn': process_text_image_btn,
            'text_only_input': text_only_input,
            'process_text_btn': process_text_btn
        }
    
    def create_video_options(self):
        """åˆ›å»ºè§†é¢‘å¤„ç†é€‰é¡¹"""
        with gr.Group():
            gr.Markdown("#### è§†é¢‘å¤„ç†é€‰é¡¹")
            
            with gr.Row():
                extract_audio = gr.Checkbox(
                    label="æå–éŸ³é¢‘",
                    value=True,
                    info="ä»è§†é¢‘ä¸­æå–éŸ³é¢‘è¿›è¡Œåˆ†æ"
                )
                
                extract_last_frame = gr.Checkbox(
                    label="ä»…æœ€åä¸€å¸§",
                    value=True,
                    info="åªæå–æœ€åä¸€å¸§å›¾åƒï¼ˆå¦åˆ™å‡åŒ€æå–å¤šå¸§ï¼‰"
                )
            
            with gr.Row():
                video_optimization = gr.Dropdown(
                    choices=VideoOptimizationPresets.list_presets(),
                    value="balanced",
                    label="è§†é¢‘ä¼˜åŒ–é¢„è®¾",
                    info="é€‰æ‹©è§†é¢‘å¤„ç†ä¼˜åŒ–çº§åˆ«"
                )
        
        return {
            'extract_audio': extract_audio,
            'extract_last_frame': extract_last_frame,
            'video_optimization': video_optimization
        }
    
    def create_output_section(self):
        """åˆ›å»ºè¾“å‡ºåŒºåŸŸ"""
        with gr.Group():
            gr.Markdown("### ğŸ“Š åˆ†æç»“æœ")
            
            with gr.Row():
                output_text = gr.Textbox(
                    label="AIåˆ†æç»“æœ",
                    lines=8,
                    max_lines=15,
                    interactive=False,
                    placeholder="åˆ†æç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
                )
            
            with gr.Tabs():
                with gr.Tab("è¯¦ç»†ä¿¡æ¯"):
                    output_json = gr.JSON(label="è¯¦ç»†ç»“æœ")
                
                with gr.Tab("å¤„ç†æ—¥å¿—"):
                    processing_log = gr.Textbox(
                        label="å¤„ç†æ—¥å¿—",
                        lines=6,
                        interactive=False
                    )
                
                with gr.Tab("æå–çš„åª’ä½“"):
                    with gr.Row():
                        extracted_audio = gr.Audio(label="æå–çš„éŸ³é¢‘", visible=False)
                        extracted_images = gr.Gallery(
                            label="æå–çš„å›¾ç‰‡",
                            visible=False,
                            columns=3,
                            rows=2
                        )
            
            with gr.Row():
                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", variant="secondary")
                download_btn = gr.Button("ğŸ’¾ ä¸‹è½½ç»“æœ", variant="secondary")
        
        return {
            'output_text': output_text,
            'output_json': output_json,
            'processing_log': processing_log,
            'extracted_audio': extracted_audio,
            'extracted_images': extracted_images,
            'clear_btn': clear_btn,
            'download_btn': download_btn
        }
    
    def create_system_info_section(self):
        """åˆ›å»ºç³»ç»Ÿä¿¡æ¯åŒºåŸŸ"""
        with gr.Row():
            with gr.Column():
                memory_info = gr.JSON(
                    label="å†…å­˜ä½¿ç”¨æƒ…å†µ",
                    value=self.get_current_memory_info()
                )
                
                refresh_memory_btn = gr.Button("ğŸ”„ åˆ·æ–°å†…å­˜ä¿¡æ¯", variant="secondary")
            
            with gr.Column():
                model_info = gr.JSON(
                    label="æ¨¡å‹ä¿¡æ¯",
                    value=self.get_model_info()
                )
        
        # åˆ·æ–°å†…å­˜ä¿¡æ¯äº‹ä»¶
        def refresh_memory():
            return self.get_current_memory_info()
        
        refresh_memory_btn.click(
            fn=refresh_memory,
            outputs=[memory_info]
        )
        
        return {
            'memory_info': memory_info,
            'model_info': model_info,
            'refresh_memory_btn': refresh_memory_btn
        }
    
    def get_custom_css(self) -> str:
        """è·å–è‡ªå®šä¹‰CSS"""
        return """
        .gradio-container {
            max-width: 1400px !important;
            margin: 0 auto !important;
        }
        
        .input-group {
            border: 2px solid #e1e5e9;
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
        }
        
        .output-group {
            border: 2px solid #28a745;
            border-radius: 12px;
            padding: 20px;
            margin: 15px 0;
            background: linear-gradient(135deg, #f8fff9 0%, #ffffff 100%);
        }
        
        .config-group {
            border: 2px solid #ffc107;
            border-radius: 12px;
            padding: 15px;
            margin: 10px 0;
            background: linear-gradient(135deg, #fffbf0 0%, #ffffff 100%);
        }
        
        .processing {
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        """
    
    def setup_event_handlers(self, components: Dict[str, Any]):
        """è®¾ç½®äº‹ä»¶å¤„ç†å™¨"""
        # è§†é¢‘å¤„ç†
        components['process_video_btn'].click(
            fn=self.process_video_input,
            inputs=[
                components['video_input'],
                components['video_prompt'],
                components['video_options']['extract_audio'],
                components['video_options']['extract_last_frame'],
                components['video_options']['video_optimization']
            ],
            outputs=[
                components['outputs']['output_text'],
                components['outputs']['output_json'],
                components['outputs']['processing_log'],
                components['outputs']['extracted_audio'],
                components['outputs']['extracted_images']
            ]
        )
        
        # éŸ³é¢‘+å›¾ç‰‡å¤„ç†
        components['process_audio_image_btn'].click(
            fn=self.process_audio_image_input,
            inputs=[
                components['audio_input'],
                components['image_input_1'],
                components['audio_image_prompt']
            ],
            outputs=[
                components['outputs']['output_text'],
                components['outputs']['output_json'],
                components['outputs']['processing_log']
            ]
        )
        
        # æ–‡æœ¬+å›¾ç‰‡å¤„ç†
        components['process_text_image_btn'].click(
            fn=self.process_text_image_input,
            inputs=[
                components['text_input'],
                components['image_input_2']
            ],
            outputs=[
                components['outputs']['output_text'],
                components['outputs']['output_json'],
                components['outputs']['processing_log']
            ]
        )
        
        # çº¯æ–‡æœ¬å¤„ç†
        components['process_text_btn'].click(
            fn=self.process_text_input,
            inputs=[components['text_only_input']],
            outputs=[
                components['outputs']['output_text'],
                components['outputs']['output_json'],
                components['outputs']['processing_log']
            ]
        )
        
        # æ¸…é™¤æŒ‰é’®
        components['outputs']['clear_btn'].click(
            fn=lambda: ("", {}, "", None, []),
            outputs=[
                components['outputs']['output_text'],
                components['outputs']['output_json'],
                components['outputs']['processing_log'],
                components['outputs']['extracted_audio'],
                components['outputs']['extracted_images']
            ]
        )
    
    def process_video_input(self, video_file, prompt, extract_audio, extract_last_frame, optimization_preset):
        """å¤„ç†è§†é¢‘è¾“å…¥"""
        if not self.current_model_loaded:
            return "âŒ æ¨¡å‹æœªåŠ è½½", {}, "é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½", None, []
        
        if not video_file:
            return "âŒ è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶", {}, "é”™è¯¯ï¼šæœªä¸Šä¼ è§†é¢‘æ–‡ä»¶", None, []
        
        try:
            with self.processing_lock:
                log_messages = []
                log_messages.append("ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘...")
                
                # ä¼˜åŒ–è§†é¢‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
                handler = MemoryOptimizedVideoHandler()
                optimized_video, optimization_info = handler.auto_optimize_for_memory(video_file)
                
                if optimization_info.get('optimized'):
                    log_messages.append(f"âœ… è§†é¢‘å·²ä¼˜åŒ–: {optimization_info}")
                
                # å¤„ç†è§†é¢‘
                video_results = self.video_processor.process_video_for_model(
                    optimized_video,
                    extract_audio=extract_audio,
                    extract_last_frame=extract_last_frame
                )
                
                if not video_results['success']:
                    error_msg = f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {video_results.get('error', 'æœªçŸ¥é”™è¯¯')}"
                    return error_msg, video_results, '\n'.join(log_messages + [error_msg]), None, []
                
                log_messages.append("âœ… è§†é¢‘å¤„ç†å®Œæˆ")
                log_messages.append("ğŸ¤– å¼€å§‹AIæ¨ç†...")
                
                # AIæ¨ç†
                system_prompt = "You are Qwen, a helpful AI assistant capable of analyzing videos, audio, and images."
                
                result = self.model_manager.inference(
                    "video",
                    video_path=optimized_video,
                    prompt=prompt,
                    system_prompt=system_prompt,
                    extract_audio=extract_audio,
                    extract_last_frame=extract_last_frame
                )
                
                log_messages.append("âœ… AIæ¨ç†å®Œæˆ")
                
                # å‡†å¤‡è¾“å‡º
                extracted_images = []
                extracted_audio_file = None
                
                if video_results.get('frame_paths'):
                    extracted_images = video_results['frame_paths']
                
                if video_results.get('audio_path'):
                    extracted_audio_file = video_results['audio_path']
                
                output_data = {
                    'ai_result': result,
                    'video_info': video_results.get('video_info', {}),
                    'optimization_info': optimization_info,
                    'processing_success': True
                }
                
                return result, output_data, '\n'.join(log_messages), extracted_audio_file, extracted_images
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, {'error': str(e)}, error_msg, None, []
    
    def process_audio_image_input(self, audio_file, image_file, prompt):
        """å¤„ç†éŸ³é¢‘+å›¾ç‰‡è¾“å…¥"""
        if not self.current_model_loaded:
            return "âŒ æ¨¡å‹æœªåŠ è½½", {}, "é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½"
        
        if not audio_file or not image_file:
            return "âŒ è¯·åŒæ—¶ä¸Šä¼ éŸ³é¢‘å’Œå›¾ç‰‡æ–‡ä»¶", {}, "é”™è¯¯ï¼šç¼ºå°‘éŸ³é¢‘æˆ–å›¾ç‰‡æ–‡ä»¶"
        
        try:
            with self.processing_lock:
                log_messages = ["ğŸµ å¼€å§‹å¤„ç†éŸ³é¢‘+å›¾ç‰‡..."]
                
                # æ„å»ºæ¶ˆæ¯
                content = [
                    {"type": "audio", "audio": audio_file},
                    {"type": "image", "image": image_file}
                ]
                
                if prompt:
                    content.append({"type": "text", "text": prompt})
                
                messages = [
                    {
                        "role": "system", 
                        "content": [{"type": "text", "text": "You are Qwen, a helpful AI assistant."}]
                    },
                    {"role": "user", "content": content}
                ]
                
                log_messages.append("ğŸ¤– å¼€å§‹AIæ¨ç†...")
                
                result = self.model_manager.inference("multimodal", messages=messages)
                
                log_messages.append("âœ… å¤„ç†å®Œæˆ")
                
                output_data = {
                    'ai_result': result,
                    'input_type': 'audio_image',
                    'processing_success': True
                }
                
                return result, output_data, '\n'.join(log_messages)
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, {'error': str(e)}, error_msg
    
    def process_text_image_input(self, text, image_file):
        """å¤„ç†æ–‡æœ¬+å›¾ç‰‡è¾“å…¥"""
        if not self.current_model_loaded:
            return "âŒ æ¨¡å‹æœªåŠ è½½", {}, "é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½"
        
        if not text or not image_file:
            return "âŒ è¯·è¾“å…¥æ–‡æœ¬å¹¶ä¸Šä¼ å›¾ç‰‡", {}, "é”™è¯¯ï¼šç¼ºå°‘æ–‡æœ¬æˆ–å›¾ç‰‡"
        
        try:
            with self.processing_lock:
                log_messages = ["ğŸ“ å¼€å§‹å¤„ç†æ–‡æœ¬+å›¾ç‰‡..."]
                
                messages = [
                    {
                        "role": "system",
                        "content": [{"type": "text", "text": "You are Qwen, a helpful AI assistant."}]
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": text},
                            {"type": "image", "image": image_file}
                        ]
                    }
                ]
                
                log_messages.append("ğŸ¤– å¼€å§‹AIæ¨ç†...")
                
                result = self.model_manager.inference("multimodal", messages=messages)
                
                log_messages.append("âœ… å¤„ç†å®Œæˆ")
                
                output_data = {
                    'ai_result': result,
                    'input_type': 'text_image',
                    'processing_success': True
                }
                
                return result, output_data, '\n'.join(log_messages)
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, {'error': str(e)}, error_msg
    
    def process_text_input(self, text):
        """å¤„ç†çº¯æ–‡æœ¬è¾“å…¥"""
        if not self.current_model_loaded:
            return "âŒ æ¨¡å‹æœªåŠ è½½", {}, "é”™è¯¯ï¼šæ¨¡å‹æœªåŠ è½½"
        
        if not text:
            return "âŒ è¯·è¾“å…¥æ–‡æœ¬", {}, "é”™è¯¯ï¼šæœªè¾“å…¥æ–‡æœ¬"
        
        try:
            with self.processing_lock:
                log_messages = ["ğŸ’¬ å¼€å§‹å¤„ç†æ–‡æœ¬..."]
                
                messages = [
                    {
                        "role": "system",
                        "content": [{"type": "text", "text": "You are Qwen, a helpful AI assistant."}]
                    },
                    {
                        "role": "user", 
                        "content": [{"type": "text", "text": text}]
                    }
                ]
                
                log_messages.append("ğŸ¤– å¼€å§‹AIæ¨ç†...")
                
                result = self.model_manager.inference("text", messages=messages)
                
                log_messages.append("âœ… å¤„ç†å®Œæˆ")
                
                output_data = {
                    'ai_result': result,
                    'input_type': 'text_only',
                    'processing_success': True
                }
                
                return result, output_data, '\n'.join(log_messages)
                
        except Exception as e:
            error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return error_msg, {'error': str(e)}, error_msg
    
    def get_current_memory_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰å†…å­˜ä¿¡æ¯"""
        try:
            if hasattr(self, 'memory_loader'):
                return self.memory_loader.memory_manager.get_system_memory_info()
            else:
                return {"status": "å†…å­˜ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        except Exception as e:
            return {"error": str(e)}
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "model_loaded": self.current_model_loaded,
            "model_path": os.getenv("MODEL_PATH", "æœªè®¾ç½®"),
            "available_presets": InferencePresets.list_presets(),
            "memory_presets": MemoryPresets.list_presets()
        }
    
    def launch(self, **kwargs):
        """å¯åŠ¨åº”ç”¨"""
        interface = self.create_interface()
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        default_kwargs = {
            "server_name": "0.0.0.0",
            "server_port": 7860,
            "share": False,
            "debug": True,
            "show_error": True
        }
        default_kwargs.update(kwargs)
        
        try:
            logger.info("ğŸš€ å¯åŠ¨Gradioåº”ç”¨...")
            logger.info(f"ğŸ“± å¤šæ¨¡æ€AIæ¨ç†å¹³å°")
            logger.info(f"ğŸŒ è®¿é—®åœ°å€: http://localhost:{default_kwargs['server_port']}")
            
            interface.launch(**default_kwargs)
            
        except Exception as e:
            logger.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
            raise
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in self.temp_files:
                if os.path.exists(temp_file):
                    os.unlink(temp_file)
            
            # æ¸…ç†æ¨¡å‹
            if self.model_manager:
                self.model_manager.cleanup()
            
            # æ¸…ç†è§†é¢‘å¤„ç†å™¨
            if hasattr(self.video_processor, 'cleanup'):
                self.video_processor.cleanup()
            
            logger.info("èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥ç¯å¢ƒ
        if not os.getenv("MODEL_PATH"):
            logger.warning("MODEL_PATHç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
        
        # åˆ›å»ºåº”ç”¨
        app = GradioApp()
        
        # å¯åŠ¨åº”ç”¨
        app.launch()
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨æ¸…ç†...")
    except Exception as e:
        logger.error(f"åº”ç”¨è¿è¡Œå¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()