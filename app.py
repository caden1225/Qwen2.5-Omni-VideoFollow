#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen2.5-Omni å¤šæ¨¡æ€æ¨ç†åº”ç”¨ä¸»å…¥å£
æ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—ï¼Œæä¾›å®Œæ•´çš„å¤šæ¨¡æ€AIæœåŠ¡
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "qwen-omni-utils" / "src"))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from gradio_app import GradioApp
from model_inference import ModelManager, InferencePresets, load_model
from memory_manager import MemoryPresets, auto_configure_memory
from video_optimizer import VideoOptimizationPresets
from test_integrated_system import IntegratedSystemTester

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class Qwen25OmniApp:
    """Qwen2.5-Omniåº”ç”¨ä¸»ç±»"""
    
    def __init__(self, args):
        self.args = args
        self.setup_environment()
        self.validate_setup()
    
    def setup_environment(self):
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        # è®¾ç½®æ¨¡å‹è·¯å¾„
        if self.args.model_path:
            os.environ['MODEL_PATH'] = self.args.model_path
        elif not os.getenv('MODEL_PATH'):
            default_path = "/home/caden/workplace/models/Qwen2.5-Omni-3B"
            os.environ['MODEL_PATH'] = default_path
            logger.warning(f"æœªè®¾ç½®MODEL_PATHï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {default_path}")
        
        # è®¾ç½®CUDAç¯å¢ƒ
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        (project_root / "outputs").mkdir(exist_ok=True)
        (project_root / "configs").mkdir(exist_ok=True)
        (project_root / "logs").mkdir(exist_ok=True)
        
        logger.info(f"ç¯å¢ƒè®¾ç½®å®Œæˆï¼Œæ¨¡å‹è·¯å¾„: {os.getenv('MODEL_PATH')}")
    
    def validate_setup(self):
        """éªŒè¯è®¾ç½®"""
        model_path = os.getenv('MODEL_PATH')
        
        if not os.path.exists(model_path):
            logger.error(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            logger.error("è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„è®¾ç½®æˆ–ä¸‹è½½æ¨¡å‹")
            if not self.args.skip_validation:
                sys.exit(1)
        
        logger.info("âœ… è®¾ç½®éªŒè¯é€šè¿‡")
    
    def run_tests(self):
        """è¿è¡Œç³»ç»Ÿæµ‹è¯•"""
        logger.info("ğŸ§ª è¿è¡Œç³»ç»Ÿæµ‹è¯•...")
        tester = IntegratedSystemTester()
        tester.run_all_tests()
        
        # æ£€æŸ¥æµ‹è¯•ç»“æœ
        passed = sum(1 for r in tester.test_results.values() if r.get("status") == "passed")
        total = len(tester.test_results)
        
        logger.info(f"æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
        
        if passed < total and not self.args.ignore_test_failures:
            logger.error("ç³»ç»Ÿæµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œå»ºè®®æ£€æŸ¥é…ç½®")
            if not self.args.force_start:
                return False
        
        return True
    
    def start_gradio_app(self):
        """å¯åŠ¨Gradioåº”ç”¨"""
        try:
            logger.info("ğŸš€ å¯åŠ¨Gradioå¤šæ¨¡æ€æ¨ç†ç•Œé¢...")
            
            app = GradioApp()
            
            # å¯åŠ¨å‚æ•°
            launch_kwargs = {
                "server_name": self.args.host,
                "server_port": self.args.port,
                "share": self.args.share,
                "debug": self.args.debug,
                "show_error": True
            }
            
            app.launch(**launch_kwargs)
            
        except Exception as e:
            logger.error(f"Gradioåº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
            raise
    
    def print_system_info(self):
        """æ‰“å°ç³»ç»Ÿä¿¡æ¯"""
        try:
            import torch
            
            print("\n" + "="*60)
            print("ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯")
            print("="*60)
            print(f"Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
            print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
            print(f"æ¨¡å‹è·¯å¾„: {os.getenv('MODEL_PATH')}")
            
            if torch.cuda.is_available():
                print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
                print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
                for i in range(torch.cuda.device_count()):
                    props = torch.cuda.get_device_properties(i)
                    memory_gb = props.total_memory / 1024**3
                    print(f"GPU {i}: {props.name} ({memory_gb:.1f}GB)")
            else:
                print("CUDA: ä¸å¯ç”¨")
            
            print(f"\nğŸ“‹ å¯ç”¨é¢„è®¾:")
            print(f"æ¨¡å‹é¢„è®¾: {', '.join(InferencePresets.list_presets())}")
            print(f"å†…å­˜é¢„è®¾: {', '.join(MemoryPresets.list_presets())}")
            print(f"è§†é¢‘é¢„è®¾: {', '.join(VideoOptimizationPresets.list_presets())}")
            print("="*60)
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿä¿¡æ¯è·å–å¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        try:
            # æ‰“å°ç³»ç»Ÿä¿¡æ¯
            if not self.args.quiet:
                self.print_system_info()
            
            # è¿è¡Œæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.args.run_tests:
                if not self.run_tests():
                    logger.error("ç³»ç»Ÿæµ‹è¯•å¤±è´¥")
                    if not self.args.force_start:
                        return False
            
            # å¯åŠ¨åº”ç”¨
            if self.args.mode == "gradio":
                self.start_gradio_app()
            elif self.args.mode == "test":
                return self.run_tests()
            else:
                logger.error(f"æœªçŸ¥æ¨¡å¼: {self.args.mode}")
                return False
            
            return True
            
        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­åº”ç”¨")
            return True
        except Exception as e:
            logger.error(f"åº”ç”¨è¿è¡Œå¤±è´¥: {e}")
            return False

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Qwen2.5-Omni å¤šæ¨¡æ€æ¨ç†åº”ç”¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python app.py                                    # ä½¿ç”¨é»˜è®¤è®¾ç½®å¯åŠ¨
  python app.py --model-path /path/to/model       # æŒ‡å®šæ¨¡å‹è·¯å¾„
  python app.py --port 8080 --host 0.0.0.0       # è‡ªå®šä¹‰æœåŠ¡å™¨è®¾ç½®
  python app.py --mode test                       # åªè¿è¡Œæµ‹è¯•
  python app.py --run-tests --force-start         # è¿è¡Œæµ‹è¯•åå¼ºåˆ¶å¯åŠ¨
        """
    )
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument(
        "--model-path",
        type=str,
        default=None,
        help="æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡MODEL_PATHè¯»å–ï¼‰"
    )
    
    parser.add_argument(
        "--mode",
        choices=["gradio", "test"],
        default="gradio",
        help="è¿è¡Œæ¨¡å¼ï¼ˆé»˜è®¤: gradioï¼‰"
    )
    
    # GradioæœåŠ¡å™¨å‚æ•°
    parser.add_argument(
        "--host",
        type=str,
        default="0.0.0.0",
        help="æœåŠ¡å™¨ä¸»æœºåœ°å€ï¼ˆé»˜è®¤: 0.0.0.0ï¼‰"
    )
    
    parser.add_argument(
        "--port",
        type=int,
        default=7860,
        help="æœåŠ¡å™¨ç«¯å£ï¼ˆé»˜è®¤: 7860ï¼‰"
    )
    
    parser.add_argument(
        "--share",
        action="store_true",
        help="å¯ç”¨Gradioå…¬å…±é“¾æ¥åˆ†äº«"
    )
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument(
        "--run-tests",
        action="store_true",
        help="å¯åŠ¨å‰è¿è¡Œç³»ç»Ÿæµ‹è¯•"
    )
    
    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="è·³è¿‡è®¾ç½®éªŒè¯"
    )
    
    parser.add_argument(
        "--ignore-test-failures",
        action="store_true",
        help="å¿½ç•¥æµ‹è¯•å¤±è´¥"
    )
    
    parser.add_argument(
        "--force-start",
        action="store_true",
        help="å³ä½¿æµ‹è¯•å¤±è´¥ä¹Ÿå¼ºåˆ¶å¯åŠ¨"
    )
    
    # è°ƒè¯•å‚æ•°
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¯ç”¨è°ƒè¯•æ¨¡å¼"
    )
    
    parser.add_argument(
        "--quiet",
        action="store_true", 
        help="å®‰é™æ¨¡å¼ï¼ˆå‡å°‘è¾“å‡ºï¼‰"
    )
    
    return parser.parse_args()

def setup_logging(debug: bool = False, quiet: bool = False):
    """è®¾ç½®æ—¥å¿—"""
    if quiet:
        level = logging.WARNING
    elif debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    
    # é‡æ–°é…ç½®root logger
    logging.getLogger().setLevel(level)
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
    log_file = project_root / "logs" / "app.log"
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    
    # è®¾ç½®æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(formatter)
    
    # æ·»åŠ åˆ°root logger
    logging.getLogger().addHandler(file_handler)

def main():
    """ä¸»å‡½æ•°"""
    try:
        # è§£æå‚æ•°
        args = parse_arguments()
        
        # è®¾ç½®æ—¥å¿—
        setup_logging(args.debug, args.quiet)
        
        # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
        app = Qwen25OmniApp(args)
        success = app.run()
        
        if success:
            logger.info("ğŸ‰ åº”ç”¨è¿è¡ŒæˆåŠŸ")
        else:
            logger.error("âŒ åº”ç”¨è¿è¡Œå¤±è´¥")
        
        return success
        
    except Exception as e:
        logger.error(f"åº”ç”¨å¯åŠ¨å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)